{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Aula de Processamento de Linguagem Natural**\n",
        "\n",
        "Professor: Leandro Romualdo \n",
        "\n",
        "Data: 17/04/2023\n",
        "\n",
        "Contato: leandroromualdo@uni9.pro.br\n",
        "\n",
        "Nesta aula vamos criar um classificador de textos, usaremos duas classes e faremos um exercício com 10 classes. "
      ],
      "metadata": {
        "id": "dcwyLMOlosFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Bibliotecas**"
      ],
      "metadata": {
        "id": "Pg0tn6BopNul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups # dataset de texto para classificação contendo 20 classes\n",
        "import pandas as pd \n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer # carrega Vectorizer e TFIDF\n",
        "from sklearn.naive_bayes import MultinomialNB # algoritmo do Naive Bayes\n",
        "from sklearn.pipeline import Pipeline # Cria pipeline contendo todas as transformações e modelo\n",
        "from nltk.stem.snowball import SnowballStemmer # Função que retorna a palavra a sua raiz\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier # Algoritmo Gradient Descendente Stocastico\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import nltk \n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "#nltk.download()"
      ],
      "metadata": {
        "id": "wXmE6bNso_Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Carrega Dataset**"
      ],
      "metadata": {
        "id": "PEl-QHS3q6xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups = fetch_20newsgroups(subset='train') # Carrega o dataset de treinamento do fetch 20 news groups"
      ],
      "metadata": {
        "id": "8WhU9MG3qssq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(newsgroups.target_names) # retorna as classes disponíveis para treinamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_nRR-PxrDkn",
        "outputId": "5536e4f0-eed2-4026-e47e-abac8c003d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian'] # Lista com as classes que vamos trabalhar\n",
        "df_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "df_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True)"
      ],
      "metadata": {
        "id": "EPIKuQx3rMgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.target_names # Apresenta as classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjbQES9IsVza",
        "outputId": "7eda0260-3be6-4a22-aae2-d28658d462f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'soc.religion.christian']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(df_train.data[1].split(\"\\n\")[:30]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A29JPSg6sZrs",
        "outputId": "179d0552-f70b-4cfd-aaf1-154db567cd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: marshall@csugrad.cs.vt.edu (Kevin Marshall)\n",
            "Subject: Re: some thoughts.\n",
            "Organization: Virginia Tech Computer Science Dept, Blacksburg, VA\n",
            "Lines: 72\n",
            "NNTP-Posting-Host: csugrad.cs.vt.edu\n",
            "Keywords: Dan Bissell\n",
            "\n",
            "bissda@saturn.wwc.edu (DAN LAWRENCE BISSELL) writes:\n",
            "\n",
            ">\tSome reasons why he wouldn't be a liar are as follows.  Who would \n",
            ">die for a lie?  Wouldn't people be able to tell if he was a liar?  People \n",
            ">gathered around him and kept doing it, many gathered from hearing or seeing \n",
            ">someone who was or had been healed.  Call me a fool, but I believe he did \n",
            ">heal people.  \n",
            "\n",
            "Anyone who dies for a \"cause\" runs the risk of dying for a lie.  As for\n",
            "people being able to tell if he was a liar, well, we've had grifters and\n",
            "charlatans since the beginning of civilization.  If David Copperfield had\n",
            "been the Messiah, I bet he could have found plenty of believers.  \n",
            "Jesus was hardly the first to claim to be a faith healer, and he wasn't the\n",
            "first to be \"witnessed.\"  What sets him apart?\n",
            "\n",
            ">\tNiether was he a lunatic.  Would more than an entire nation be drawn \n",
            ">to someone who was crazy.  Very doubtful, in fact rediculous.  For example \n",
            ">anyone who is drawn to David Koresh is obviously a fool, logical people see \n",
            ">this right away.\n",
            "\n",
            "Rubbish.  Nations have followed crazies, liars, psychopaths, and \n",
            "megalomaniacs throughout history.  Hitler, Tojo, Mussolini, Khomeini,\n",
            "Qadaffi, Stalin, Papa Doc, and Nixon come to mind...all from this century.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Feature Enginnering** "
      ],
      "metadata": {
        "id": "tQdO2ybMs1qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converta uma coleção de documentos de texto em uma matriz de contagem de tokens\n",
        "# Essa implementação produz uma representação esparsa das contagens\n",
        "\n",
        "count_vect = CountVectorizer() # Instancia o algoritmo do count vectorizer\n",
        "X_train_counts = count_vect.fit_transform(df_train.data)\n",
        "X_train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbq0EiNrsplk",
        "outputId": "f50e00c5-31a3-4965-c7d4-d4cefc196a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1079, 19666)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF \n",
        "tfidf_transformer = TfidfTransformer() \n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
      ],
      "metadata": {
        "id": "v-YnA6UGtZ2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Abordagem 1**\n",
        "\n",
        "#### **Treinamento do modelo**"
      ],
      "metadata": {
        "id": "OKZ8yiTNt3dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB() # Instancia o algoritmo Naive Bayes para treinamento\n",
        "clf.fit(X_train_tfidf, df_train.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "oAq3aZmUtuDx",
        "outputId": "b5da730a-bb39-4113-df0b-bf009bc33ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline de machine learning \n",
        "clf_1 = Pipeline([\n",
        "    ('vect', CountVectorizer()),    # Passo 1, aplicar o count vectorizer nos textos \n",
        "    ('tfidf', TfidfTransformer()),  # Passo 2, aplicar o TFIDF nos textos\n",
        "    ('clf', MultinomialNB())])      # Passo 3, aplicar o algoritmo Naive Bayes"
      ],
      "metadata": {
        "id": "IHI3rUukuH7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_trained = clf_1.fit(df_train.data, df_train.target) # Realiza o treinamento do modelo no pipeline"
      ],
      "metadata": {
        "id": "RN_8BJrjuPFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = clf_trained.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "YxdneRNFwg3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_kzwN4ywto8",
        "outputId": "9de17667-b1ae-4286-d596-fad61e27fff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.8521617852161785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gera as métricas de assertividade do modelo\n",
        "creport = classification_report(df_test.target, pred, target_names=df_test.target_names)\n",
        "print(creport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fUGcB76w6Kc",
        "outputId": "0a06c58f-e149-4ae0-f5f5-dad244fd268b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.99      0.68      0.80       319\n",
            "soc.religion.christian       0.79      0.99      0.88       398\n",
            "\n",
            "              accuracy                           0.85       717\n",
            "             macro avg       0.89      0.83      0.84       717\n",
            "          weighted avg       0.88      0.85      0.85       717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_confusion_matrix(clf_trained, df_test.data, df_test.target, labels=clf_trained.classes_)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "fsi1c3wOxJw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tuning de parametros**\n",
        "\n",
        "#### Modelo usando **Naive bayes** com Grid Search"
      ],
      "metadata": {
        "id": "x5bl9L-BzDA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "# Aqui, estamos criando uma lista de parâmetros para os quais gostaríamos de fazer o ajuste de desempenho.\n",
        "# Todos os nomes dos parâmetros começam com o nome do classificador (lembre-se do nome arbitrário que demos).\n",
        "# Por exemplo. vect__ngram_range; aqui estamos dizendo para usar unigramas e bigramas e escolher aquele que é o ideal.\n",
        "\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
      ],
      "metadata": {
        "id": "RoZd3_jZyytB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf = GridSearchCV(clf_trained, parameters, n_jobs=-1) # Define o grid search para buscar os melhores parametros \n",
        "gs_clf = gs_clf.fit(df_train.data, df_train.target) # treinamento do modelo "
      ],
      "metadata": {
        "id": "K3uzJggez4qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para ver a melhor pontuação média e os parâmetros, execute o seguinte código\n",
        "\n",
        "print(gs_clf.best_score_)\n",
        "gs_clf.best_params_\n",
        "\n",
        "#A saída acima deve ser: A precisão agora aumentou para ~90,6% para o classificador NB (não tão ingênuo mais! 😄)\n",
        "# e os parâmetros correspondentes são {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajgZdm8D4w0z",
        "outputId": "cefa4c19-7bd5-4a3e-b014-5912b0604e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9823901808785529\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = gs_clf.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "eRSK5-Hr4wwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcltvwbS5QtE",
        "outputId": "33ef405e-9358-4954-9ad7-1a5f3b00b19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.9539748953974896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creport = classification_report(df_test.target, pred, target_names=df_test.target_names)\n",
        "print(creport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcP3adoP5QxZ",
        "outputId": "b7416199-c501-4ca4-825b-e37e2da4bf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.99      0.91      0.95       319\n",
            "soc.religion.christian       0.93      0.99      0.96       398\n",
            "\n",
            "              accuracy                           0.95       717\n",
            "             macro avg       0.96      0.95      0.95       717\n",
            "          weighted avg       0.96      0.95      0.95       717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abordagem II**"
      ],
      "metadata": {
        "id": "7gilwINhyLyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline de machine learning \n",
        "clf_2 = Pipeline([\n",
        "    ('vect', CountVectorizer()), # Passo 1, aplicar o count vectorizer nos textos \n",
        "    ('tfidf', TfidfTransformer()), # Passo 2, aplicar o TFIDF nos textos\n",
        "    ('clf-svm', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=25, random_state=42))]) # Passo 3, aplicar o algoritmo Naive Bayes"
      ],
      "metadata": {
        "id": "k8-wEaMrxm4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_trained = clf_2.fit(df_train.data, df_train.target) # realiza o treinamento do modelo no pipeline"
      ],
      "metadata": {
        "id": "cFdWSSg0ykqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = svm_trained.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "a3J0AxTbyqmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlcx8a8lyus-",
        "outputId": "b1515900-11ec-4346-d896-f3163103313a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.9330543933054394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Tuning de parametros**\n",
        "\n",
        "#### Modelo usando **SGD** com Grid Search"
      ],
      "metadata": {
        "id": "bpUDToq75vVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}"
      ],
      "metadata": {
        "id": "B1eDG34Y0bQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf_svm = GridSearchCV(svm_trained, parameters_svm, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(df_train.data, df_train.target)"
      ],
      "metadata": {
        "id": "v80FDo1z59LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assertividade e melhores parametros\n",
        "print(gs_clf_svm.best_score_)\n",
        "gs_clf_svm.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hevKZEw6RRv",
        "outputId": "fe28a03b-1f49-4ff5-a613-2e330128d341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9805297157622739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = gs_clf_svm.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "-oGWAp2C6bK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCxaBZRT6kHA",
        "outputId": "82814e00-ffaa-4710-c6d8-5c276cc329ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.9428172942817294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creport = classification_report(df_test.target, pred, target_names=df_test.target_names)\n",
        "print(creport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu1nbrV16nB2",
        "outputId": "a79cca4f-d0bd-482b-e37d-6c402e477c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.99      0.88      0.93       319\n",
            "soc.religion.christian       0.91      0.99      0.95       398\n",
            "\n",
            "              accuracy                           0.94       717\n",
            "             macro avg       0.95      0.94      0.94       717\n",
            "          weighted avg       0.95      0.94      0.94       717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Abordagem III**\n",
        "\n",
        "Remover os stopwords"
      ],
      "metadata": {
        "id": "UH0GaZIq6zj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_clf_stp = Pipeline([\n",
        "    ('vect', CountVectorizer(stop_words='english')),    # Passo 1, aplicar o count vectorizer nos textos excluindo stopwords\n",
        "    ('tfidf', TfidfTransformer()),  # Passo 2, aplicar o TFIDF nos textos\n",
        "    ('clf', MultinomialNB())])      # Passo 3, aplicar o algoritmo Naive Bayes"
      ],
      "metadata": {
        "id": "TWjT-FNW6sqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_clf_stp_trained = nb_clf_stp.fit(df_train.data, df_train.target) # realiza o treinamento do modelo no pipeline"
      ],
      "metadata": {
        "id": "r6bNjj717YqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = nb_clf_stp_trained.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "yNQ_qyiG7eOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('Accuracy = ', acc)\n",
        "\n",
        "creport = classification_report(df_test.target, pred, target_names=df_test.target_names)\n",
        "print(creport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSekEl8v7u2k",
        "outputId": "540ad6f4-35ea-4cd2-b03a-d62d31c79871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.9065550906555091\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.98      0.80      0.88       319\n",
            "soc.religion.christian       0.86      0.99      0.92       398\n",
            "\n",
            "              accuracy                           0.91       717\n",
            "             macro avg       0.92      0.90      0.90       717\n",
            "          weighted avg       0.92      0.91      0.91       717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_clf_tuned = GridSearchCV(nb_clf_stp_trained, parameters, n_jobs=-1) # Define o grid search para buscar os melhores parametros \n",
        "nb_clf_tuned = nb_clf_tuned.fit(df_train.data, df_train.target) # treinamento do modelo "
      ],
      "metadata": {
        "id": "5QYm64pm70dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assertividade e melhores parametros\n",
        "print(nb_clf_tuned.best_score_)\n",
        "nb_clf_tuned.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0868f2f-c200-4d11-e822-7513cbc612f0",
        "id": "vRoAx4Ko8Lca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9870198105081824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = nb_clf_tuned.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "EKO3djcM8Lcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a752c564-39ba-4191-b7ad-7a6545cc4ff8",
        "id": "4ev5ROhC8Lcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.9693165969316597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creport = classification_report(df_test.target, pred, target_names=df_test.target_names)\n",
        "print(creport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8744630-bf99-4a75-a836-2bc671b66de3",
        "id": "mhSosXxU8Lcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.98      0.95      0.96       319\n",
            "soc.religion.christian       0.96      0.99      0.97       398\n",
            "\n",
            "              accuracy                           0.97       717\n",
            "             macro avg       0.97      0.97      0.97       717\n",
            "          weighted avg       0.97      0.97      0.97       717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Abordagem IV\n",
        "Stopword com SVM"
      ],
      "metadata": {
        "id": "-A7hiGmi8lIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline de machine learning \n",
        "svm_stp_clf = Pipeline([\n",
        "    ('vect', CountVectorizer(stop_words='english')), # Passo 1, aplicar o count vectorizer nos textos \n",
        "    ('tfidf', TfidfTransformer()), # Passo 2, aplicar o TFIDF nos textos\n",
        "    ('clf-svm', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=25, random_state=42))]) # Passo 3, aplicar o algoritmo Naive Bayes"
      ],
      "metadata": {
        "id": "mX2bmlWv82Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_stp_trained = svm_stp_clf.fit(df_train.data, df_train.target) # realiza o treinamento do modelo no pipeline"
      ],
      "metadata": {
        "id": "a_a7reoR82Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = svm_stp_trained.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "fmzKL8vP82Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba201ff-9c5e-45d1-9d72-a1daa49f88a7",
        "id": "9Ou8_IY782Kt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.9372384937238494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_stp_tun = GridSearchCV(svm_stp_trained, parameters_svm, n_jobs=-1)\n",
        "svm_stp_tun = svm_stp_tun.fit(df_train.data, df_train.target)"
      ],
      "metadata": {
        "id": "Mbf5EGEF8ohR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assertividade e melhores parametros\n",
        "print(svm_stp_tun.best_score_)\n",
        "svm_stp_tun.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4587ac9-9eca-4b0c-de1b-f1978434b272",
        "id": "av8ijX6O8ohR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9842420327304048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = svm_stp_tun.predict(df_test.data) # Faz predição no dado de teste"
      ],
      "metadata": {
        "id": "cj8mhVMQ8ohR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred == df_test.target)\n",
        "print('>>>> Acurácia: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915daaa0-1744-44e8-960e-12886e2cb2bf",
        "id": "57YYPjUT8ohR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Acurácia:  0.9358437935843794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creport = classification_report(df_test.target, pred, target_names=df_test.target_names)\n",
        "print(creport)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c727e854-a3e9-4aeb-b8f1-b25a04722078",
        "id": "LkTXrO9N8ohS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.98      0.87      0.92       319\n",
            "soc.religion.christian       0.91      0.99      0.94       398\n",
            "\n",
            "              accuracy                           0.94       717\n",
            "             macro avg       0.94      0.93      0.93       717\n",
            "          weighted avg       0.94      0.94      0.94       717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercício para o Portifólio de vocês**\n",
        "\n",
        "1. Abra um colab novo \n",
        "2. Baixe o mesmo conjunto de textos que usamos nesta aula\n",
        "3. Selecione 10 classes do seu interesse \n",
        "4. Treine dois modelos, faça tuning e separe por abordagens \n",
        "\n",
        "**A entrega será somente dia 24/04. E vale 3 pontos** \n",
        "\n",
        "**Pensem que alguém vai ler este código depois de vocês fazerem**\n",
        "\n",
        "Critérios de avaliação: \n",
        "- Não vou me apegar a assertividade do modelo \n",
        "- O critério será a organização e conclusões ao longo do codigo."
      ],
      "metadata": {
        "id": "p9LB1sFwBsU6"
      }
    }
  ]
}